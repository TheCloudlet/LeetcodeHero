#+title: ML Compiler Overview

* 目標與主題
這份筆記聚焦於 ML Compiler 在 GPU 架構下的整體編譯流程，對比 NVIDIA 與 AMD 在 Compiler 架構中的差異，涵蓋以下主題：
- Tensor Graph → IR → GPU kernel 的整體 Compiler stack
- MLIR, HLO, LLVM IR, PTX, SASS, hsaco 等格式與流程
- CUDA vs ROCm 的分工與底層差異


* 高階架構圖
#+begin_example
+--------------------------------------------------------------+
|      Python Code: TensorFlow / PyTorch (Model, Train)       |
+--------------------------------------------------------------+
                              |
                              v
+--------------------------------------------------------------+
|                      Tensor Graph                            |
|          - Static (TensorFlow) / Dynamic (PyTorch)           |
+--------------------------------------------------------------+
                              |
                              v
+--------------------------------------------------------------+
|              Frontend IR Builders (Graph → IR)              |
|   - XLA (TF) / TorchScript / FX / TVM / MLIR (unified IR)   |
+--------------------------------------------------------------+
                              |
                              v
+--------------------------------------------------------------+
|             Core Intermediate Representation (IR)           |
|      - HLO (XLA) / MLIR Dialects (tf, mhlo, linalg...)      |
+--------------------------------------------------------------+
                              |
                              v
+--------------------------------------------------------------+
|        Machine Learning Compiler (Middle IR Optim)          |
|    - Graph Optimizations: fusion, tiling, layout, schedule  |
+--------------------------------------------------------------+
                              |
                              v
+------------------------+          +---------------------------+
|     NVIDIA Backend     |          |       AMD Backend         |
|------------------------|          |---------------------------|
|  MLIR → LLVM NVPTX     |          |  MLIR → LLVM AMDGPU       |
|  LLVM IR → PTX         |          |  LLVM IR (gfx)            |
|  JIT PTX → SASS        |          |  CodeGen → .hsaco         |
+------------------------+          +---------------------------+
         |                                      |
         v                                      v
+------------------------+          +-----------------------------+
|  CUDA Runtime / Driver |          |     ROCm Runtime / Driver   |
|  - Memory alloc, JIT   |          |  - Memory alloc, launcher   |
+------------------------+          +-----------------------------+
         |                                      |
         v                                      v
+------------------------+          +-----------------------------+
|    GPU Kernel Launch   |          |      GPU Kernel Launch      |
|  - Threads / Blocks    |          |    - Grid / Wavefront       |
+------------------------+          +-----------------------------+
#+end_example

* NVIDIA Compiler Stack
- 前端:
  - PyTorch / TF 等框架將模型轉成計算圖（GraphDef / TorchScript）
  - Graph → HLO（XLA）或 MLIR
- 中端:
  - XLA / MLIR 做 op fusion, layout transform 等優化
  - LLVM IR（或 Triton IR）生成
- 後端:
  - LLVM NVPTX backend 產生 PTX
  - PTX 傳遞給 CUDA driver → SASS（runtime JIT）
  - GPU 執行 kernel（block/grid/thread 配置由 driver 控制）

**常見檔案格式：**
| 層級  | 檔案類型  | 說明                           |
|-------+----------+--------------------------------|
| 中間碼 | `.ptx`   | LLVM-like GPU IR               |
| 二進位 | `.cubin` | compiled binary, JIT or static |
| 執行碼 | SASS     | 真正在 SM 上執行的機器指令         |

* AMD Compiler Stack (ROCm)
- 前端:
  - TensorFlow / PyTorch 同樣經過 MLIR / HLO 優化
- 中端:
  - MLIR / LLVM 中間碼會轉成 GPU-specific layout
- 後端:
  - 產生 LLVM IR → Amdgpu backend → `.hsaco` 檔
  - ROCm runtime 載入 `.hsaco` 並在 GPU 執行

**對應檔案格式：**
| 層級  | 檔案類型              | 說明                            |
|-------+----------------------+---------------------------------|
| 中間碼 | LLVM IR              | ROCm 支援直接轉 LLVM             |
| 二進位 | `.hsaco`             | HSA Code Object, 等價於 `.cubin` |
| 執行碼 | ISA (gfx9, gfx11...) | AMD 組語層指令                   |

* 關鍵差異與觀察
| 項目             | NVIDIA (CUDA)      | AMD (ROCm)        |
|------------------+--------------------+-------------------|
| 中間 IR          | PTX                | LLVM IR           |
| Driver 編譯      | PTX → SASS         | LLVM IR → ISA     |
| kernel binary    | .cubin (封裝 SASS) | .hsaco            |
| backend compiler | NVCC + NVPTX       | Clang-ROCm        |
| profiling 工具   | Nsight, nvprof     | rocprof, rocminfo |
| 專屬 library     | cuBLAS, cuDNN      | rocBLAS, MIOpen   |

* 延伸閱讀與實驗方向
- 使用 `TF_XLA_FLAGS=--xla_dump_to=...` 觀察 HLO IR 輸出
- 用 `nvcc -ptx`, `cuobjdump --dump-sass` 檢查實際生成的機器碼
- 使用 `mlir-opt`, `mlir-translate` 操作 MLIR dialect
- 分析一段 kernel 對應的 GPU block/thread mapping 設計

* Possible bottle neck
TODO
* How to adjust or opt.
TODO



// RISC-V
// Manual``
// register --> pc,


// if () {
} else {
}

eq %1 %2
...
..
..
..

jump tag:


// malloc a --> b

mmap() <-- C

for (int i; i < N; i++) {
        // read ...
        //
}


|----------|----------|-----------|-----------|

m1
<---------->
            <-->op
                 <---------->


<---------->
  <---------->
    <---------->
      <---------->
        <---------->
                    <--> op
                      <--> op2 ... 3

// register num--
// brach prediction


pass:
  --> Val Propagation

  int a = 5
  b = a --> 5
  c = b --> 5

  VHDL

     c (9)
     |
     b (9)
   |   |
a(5)   z(4)


a (next->partition:b[0])

              a              --> 100,0000
            a1  a2           // db a1--b  a2--c <-- lookup
           /      |
          /        \
        b[0]  b[1] b[2]         c
       b1  b2      c1 c2

b --> a.a1.b

// 25hr --> 15min


// Phase 1:  string --``> hash liner probing hash fuction + hash probing

25hour 10 hour

// Phase 2,3:
// generate-for   [0..1024] * [0..1024] 2^20
// VHDL-->Verilog
// 10hour --> 15

C++:
C89 C99 C++11 ~ C++17

lambda [&]()

if (int a = xxx; a < 3) {

}

for_each(it.)

// partital specialization
//
//


* This job is to profile compare NVIDIA / AMD find bottleneck. Propose 